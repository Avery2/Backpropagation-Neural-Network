# Backpropagation-Nueral-Network

Wrote this program the summer after graduating high school. It was the cumulation of basic programming skills I had into my first big project.

This project was to make a neural network from scratch without libraries. It learned to classify handwritten digits from the MNIST database. I didn't know how to use git correctly so its currently broken. At some point it learned to have about 15-20% accurancy which is better than the 10% you would get from guessing but is still pretty bad.

I used the following sources to learn:

* [MNIST database for handwritten digits](http://yann.lecun.com/exdb/mnist/)
* Amazing videos on neural networks by Grant Sanderson on [his website](https://www.3blue1brown.com/neural-networks) and [YouTube Channel](https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi)
* [Khan Acedemy Multivariable Calculus Class](https://www.khanacademy.org/math/multivariable-calculus) (also taught by Grant Sanderson)
* [Wikipedia](https://en.wikipedia.org/wiki/Neural_network)
